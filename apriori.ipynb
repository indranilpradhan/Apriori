{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "apriori.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6kKE09xDCl9"
      },
      "source": [
        "import csv\n",
        "import json\n",
        "from itertools import combinations\n",
        "import threading\n",
        "import math\n",
        "from multiprocessing.pool import ThreadPool as Pool\n",
        "import datetime\n",
        "from apyori import apriori\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f1PvzYMMf2Q"
      },
      "source": [
        "##Transaction Reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Askp2y7IOX9M"
      },
      "source": [
        "freq_itemset = {}\n",
        "def gen_tr_freq_itemset(D,sot,minsup):\n",
        "  L = []\n",
        "  C = {}\n",
        "  total_count = 0\n",
        "  total_ele = 0\n",
        "  min_sup = minsup\n",
        "  for key,value in D.items():\n",
        "    for j in value:\n",
        "      count = 0\n",
        "      for key1,value1 in D.items():\n",
        "        if j in value1:\n",
        "          count = count+1\n",
        "      temp = [j]\n",
        "      C[json.dumps(temp)] = count\n",
        "      \n",
        "  for k,v in C.items():\n",
        "    support = C[k]/len(D.keys())\n",
        "    if support >= min_sup:\n",
        "      L.append(json.loads(k))\n",
        "\n",
        "  k = 2\n",
        "  while True:\n",
        "    if len(L) == 0:\n",
        "      break\n",
        "    for i,j in sot.items():\n",
        "      if sot[i] <= k-1:\n",
        "        del D[i]\n",
        "    freq = []\n",
        "    in_freq = []\n",
        "    for i,j in C.items():\n",
        "      lst = json.loads(i)\n",
        "      if lst in L:\n",
        "        for ele in lst:\n",
        "          freq.append(ele)\n",
        "      else:\n",
        "        for ele in lst:\n",
        "          in_freq.append(ele)\n",
        "\n",
        "    diff_list = list(list(set(in_freq)-set(freq)))\n",
        "    for ele in diff_list:\n",
        "      for key,value in D.items():\n",
        "        if ele in value:\n",
        "          value.remove(ele)\n",
        "\n",
        "    sot = {}\n",
        "    for key,value in D.items():\n",
        "      sot[key] = len(value)\n",
        "    temp_L = []\n",
        "    for i in range(len(L)):\n",
        "      for j in range(i+1,len(L)):\n",
        "        mismatch = 0\n",
        "        for index in range(k-1):\n",
        "          if k-1 > 0 and L[i][index] != L[j][index]:\n",
        "            mismatch += 1\n",
        "        if mismatch <= 1:\n",
        "          u_list = list(set().union(L[i],L[j]))\n",
        "          comb = list(combinations(u_list,k-1))\n",
        "          flag = 0\n",
        "          for element in comb:\n",
        "            t_ele = sorted(list(element))\n",
        "            if t_ele not in L:\n",
        "              flag = 1\n",
        "              break\n",
        "          if flag == 0:\n",
        "            temp_L.append(u_list)\n",
        "    C_old = C.copy()\n",
        "    L_old = L.copy()\n",
        "  \n",
        "    for element in L_old:\n",
        "      ele = json.dumps(element)\n",
        "      if ele in freq_itemset:\n",
        "        freq_itemset[ele] += C_old[ele]\n",
        "      else:\n",
        "        freq_itemset[ele] = C_old[ele]\n",
        "\n",
        "    C= {}\n",
        "    L = []\n",
        "    for i in temp_L:\n",
        "      count = 0\n",
        "      for key,value in D.items():\n",
        "        if (set(i).issubset(set(value))):\n",
        "          count += 1\n",
        "      C[json.dumps(sorted(i))] = count\n",
        "    \n",
        "    for key,value in C.items():\n",
        "      support = C[key]/len(D.keys())\n",
        "      if support >= min_sup:\n",
        "        L.append(sorted(json.loads(key)))\n",
        "    k += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1MbX0d5iKla"
      },
      "source": [
        "##Sign"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZbyObW-lmF_"
      },
      "source": [
        "**0.9**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inYOixfslo6e"
      },
      "source": [
        "D = {}\n",
        "sot = {}\n",
        "min_sup = 0.9\n",
        "with open('/content/data/sign.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    index = 0\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        sot[str(index)] = len(temp)\n",
        "        D[str(index)] = temp\n",
        "        index += 1\n",
        "start = datetime.datetime.now()\n",
        "total_ele = len(D.keys())\n",
        "gen_tr_freq_itemset(D,sot,min_sup)\n",
        "end = datetime.datetime.now()\n",
        "diff = end - start\n",
        "freq = []\n",
        "for key,value in freq_itemset.items():\n",
        "  support = freq_itemset[key]/total_ele\n",
        "  if support >= min_sup:\n",
        "    freq.append(json.loads(key))\n",
        "print(freq)\n",
        "print(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCJhHRVgljET"
      },
      "source": [
        "**0.8**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL5DDwteNjqL"
      },
      "source": [
        "D = {}\n",
        "sot = {}\n",
        "min_sup = 0.8\n",
        "with open('/content/data/sign.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    index = 0\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        sot[str(index)] = len(temp)\n",
        "        D[str(index)] = temp\n",
        "        index += 1\n",
        "start = datetime.datetime.now()\n",
        "total_ele = len(D.keys())\n",
        "gen_tr_freq_itemset(D,sot,min_sup)\n",
        "end = datetime.datetime.now()\n",
        "diff = end - start\n",
        "freq = []\n",
        "for key,value in freq_itemset.items():\n",
        "  support = freq_itemset[key]/total_ele\n",
        "  if support >= min_sup:\n",
        "    freq.append(json.loads(key))\n",
        "print(freq)\n",
        "print(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d71cCW_1lzrL"
      },
      "source": [
        "**0.7**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht4IzJJ3l1G7"
      },
      "source": [
        "D = {}\n",
        "sot = {}\n",
        "min_sup = 0.7\n",
        "with open('/content/data/sign.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    index = 0\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        sot[str(index)] = len(temp)\n",
        "        D[str(index)] = temp\n",
        "        index += 1\n",
        "start = datetime.datetime.now()\n",
        "total_ele = len(D.keys())\n",
        "gen_tr_freq_itemset(D,sot,min_sup)\n",
        "end = datetime.datetime.now()\n",
        "diff = end - start\n",
        "freq = []\n",
        "for key,value in freq_itemset.items():\n",
        "  support = freq_itemset[key]/total_ele\n",
        "  if support >= min_sup:\n",
        "    freq.append(json.loads(key))\n",
        "print(freq)\n",
        "print(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FerfkgAji_jV"
      },
      "source": [
        "##Leviathan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8AaT5Ucnkte"
      },
      "source": [
        "**0.7**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucQRcgerjCfH"
      },
      "source": [
        "D = {}\n",
        "sot = {}\n",
        "min_sup = 0.7\n",
        "with open('/content/data/Leviathan.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    index = 0\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        sot[str(index)] = len(temp)\n",
        "        D[str(index)] = temp\n",
        "        index += 1\n",
        "start = datetime.datetime.now()\n",
        "total_ele = len(D.keys())\n",
        "gen_tr_freq_itemset(D,sot,min_sup)\n",
        "end = datetime.datetime.now()\n",
        "diff = end - start\n",
        "freq = []\n",
        "for key,value in freq_itemset.items():\n",
        "  support = freq_itemset[key]/total_ele\n",
        "  if support >= min_sup:\n",
        "    freq.append(json.loads(key))\n",
        "print(freq)\n",
        "print(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWMLdzRrrCy8"
      },
      "source": [
        "**0.6**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55QEIcfErF8n"
      },
      "source": [
        "D = {}\n",
        "sot = {}\n",
        "min_sup = 0.6\n",
        "with open('/content/data/Leviathan.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    index = 0\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        sot[str(index)] = len(temp)\n",
        "        D[str(index)] = temp\n",
        "        index += 1\n",
        "start = datetime.datetime.now()\n",
        "total_ele = len(D.keys())\n",
        "gen_tr_freq_itemset(D,sot,min_sup)\n",
        "end = datetime.datetime.now()\n",
        "diff = end - start\n",
        "freq = []\n",
        "for key,value in freq_itemset.items():\n",
        "  support = freq_itemset[key]/total_ele\n",
        "  if support >= min_sup:\n",
        "    freq.append(json.loads(key))\n",
        "print(freq)\n",
        "print(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnqA-ayitwYM"
      },
      "source": [
        "**0.5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doHgyKFstzPB"
      },
      "source": [
        "D = {}\n",
        "sot = {}\n",
        "min_sup = 0.5\n",
        "with open('/content/data/Leviathan.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    index = 0\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        sot[str(index)] = len(temp)\n",
        "        D[str(index)] = temp\n",
        "        index += 1\n",
        "start = datetime.datetime.now()\n",
        "total_ele = len(D.keys())\n",
        "gen_tr_freq_itemset(D,sot,min_sup)\n",
        "end = datetime.datetime.now()\n",
        "diff = end - start\n",
        "freq = []\n",
        "for key,value in freq_itemset.items():\n",
        "  support = freq_itemset[key]/total_ele\n",
        "  if support >= min_sup:\n",
        "    freq.append(json.loads(key))\n",
        "print(freq)\n",
        "print(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7RgbRRiM1nB"
      },
      "source": [
        "##Partitioning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FekP_SHM30g"
      },
      "source": [
        "freq_itemset_p = {}\n",
        "def gen_next_comb(L,k):\n",
        "  for i in range(len(L)):\n",
        "    for j in range(i+1,len(L)):\n",
        "      mismatch = 0\n",
        "      for index in range(len(L[i])):\n",
        "        if L[i][index] != L[j][index]:\n",
        "          mismatch += 1\n",
        "      if mismatch <= 1:\n",
        "        u_list = list(set().union(L[i],L[j]))\n",
        "        comb = list(combinations(u_list,k-1))\n",
        "        flag = 0\n",
        "        for element in comb:\n",
        "          t_ele = sorted(list(element))\n",
        "          if t_ele not in L:\n",
        "            flag = 1\n",
        "            break\n",
        "        if flag == 0:\n",
        "          yield u_list\n",
        "\n",
        "def gen_freq_itemset(partition,minsup):\n",
        "  min_count = minsup\n",
        "  \n",
        "  D = partition.copy()\n",
        "  L = []\n",
        "  C = {}\n",
        "  total_count = 0\n",
        "  total_ele = 0\n",
        "  for value in D:\n",
        "    for j in value:\n",
        "      count = 0\n",
        "      for value1 in D:\n",
        "        if j in value1:\n",
        "          count = count+1\n",
        "      temp = [j]\n",
        "      C[json.dumps(temp)] = count\n",
        "  for k,v in C.items():\n",
        "    support = C[k]/len(partition)\n",
        "    if support >= min_count:\n",
        "      t = json.loads(k)\n",
        "      L.append(t)\n",
        "\n",
        "  k = 2\n",
        "  while True:\n",
        "    if len(L) == 0:\n",
        "      break\n",
        "\n",
        "    C_old = C.copy()\n",
        "    L_old = L.copy()\n",
        "\n",
        "    for key in L_old:\n",
        "        ele = json.dumps(key)\n",
        "        if ele in freq_itemset_p:\n",
        "          freq_itemset_p[ele] += C_old[ele]\n",
        "        else:\n",
        "          freq_itemset_p[ele] = C_old[ele]\n",
        "    C= {}\n",
        "    L = []\n",
        "    for i in gen_next_comb(L_old,k):\n",
        "      count = 0\n",
        "      for value in D:\n",
        "        if (set(i).issubset(set(value))):\n",
        "          count += 1\n",
        "      C[json.dumps(sorted(i))] = count\n",
        "    \n",
        "    for key,value in C.items():\n",
        "      support = C[key]/len(partition)\n",
        "      if C[key] >= min_count:\n",
        "        L.append(sorted(json.loads(key)))\n",
        "\n",
        "    k += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trCT7W-_dVmX"
      },
      "source": [
        "##Sign"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ2Rzup7xmoH"
      },
      "source": [
        "**0.9**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6mRfLGemXn4"
      },
      "source": [
        "itemset = []\n",
        "with open('/content/data/sign.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        itemset.append(temp)\n",
        "\n",
        "global_min_sup = 0.9\n",
        "total_partition = 5\n",
        "global_min_count = int(len(itemset)/total_partition)\n",
        "\n",
        "time_period = []\n",
        "if total_partition == math.ceil(total_partition):\n",
        "  for i in range(total_partition):\n",
        "    start = i*global_min_count\n",
        "    end = start + global_min_count\n",
        "    if end > len(itemset):\n",
        "      end = len(itemset)\n",
        "    partition  = itemset[start:end].copy()\n",
        "    st = datetime.datetime.now()\n",
        "    temp_min_sup = (((len(itemset)*global_min_sup))/total_partition)/float(len(partition))\n",
        "    gen_freq_itemset(partition,temp_min_sup)\n",
        "    et = datetime.datetime.now()\n",
        "    diff = et-st\n",
        "    time_period.append(diff.total_seconds()/60.0)\n",
        "else:\n",
        "  total_partition = math.ceil(total_partition)\n",
        "  for i in range(total_partition):\n",
        "    start = i*global_min_count\n",
        "    end = start + global_min_count\n",
        "    if end > len(itemset):\n",
        "      end = len(itemset)\n",
        "    partition  = itemset[start:end].copy()\n",
        "    st = datetime.datetime.now()\n",
        "    temp_min_sup = (((len(itemset)*global_min_sup))/total_partition)/float(len(partition))\n",
        "    gen_freq_itemset(partition,temp_min_sup)\n",
        "    et = datetime.datetime.now()\n",
        "    diff = et-st\n",
        "    time_period.append(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9pkNXCH266A"
      },
      "source": [
        "time_period"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr5q1sngyA3e"
      },
      "source": [
        "max(time_period)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x1hBXodyGkv"
      },
      "source": [
        "**0.8**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUwEUMiEyIWM"
      },
      "source": [
        "itemset = []\n",
        "with open('/content/data/sign.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        itemset.append(temp)\n",
        "\n",
        "global_min_sup = 0.8\n",
        "total_partition = 5\n",
        "global_min_count = int(len(itemset)/total_partition)\n",
        "\n",
        "time_period = []\n",
        "if total_partition == math.ceil(total_partition):\n",
        "  for i in range(total_partition):\n",
        "    start = i*global_min_count\n",
        "    end = start + global_min_count\n",
        "    if end > len(itemset):\n",
        "      end = len(itemset)\n",
        "    partition  = itemset[start:end].copy()\n",
        "    st = datetime.datetime.now()\n",
        "    temp_min_sup = (((len(itemset)*global_min_sup))/total_partition)/float(len(partition))\n",
        "    gen_freq_itemset(partition,temp_min_sup)\n",
        "    et = datetime.datetime.now()\n",
        "    diff = et-st\n",
        "    time_period.append(diff.total_seconds()/60.0)\n",
        "else:\n",
        "  total_partition = math.ceil(total_partition)\n",
        "  for i in range(total_partition):\n",
        "    start = i*global_min_count\n",
        "    end = start + global_min_count\n",
        "    if end > len(itemset):\n",
        "      end = len(itemset)\n",
        "    partition  = itemset[start:end].copy()\n",
        "    st = datetime.datetime.now()\n",
        "    temp_min_sup = (((len(itemset)*global_min_sup))/total_partition)/float(len(partition))\n",
        "    gen_freq_itemset(partition,temp_min_sup)\n",
        "    et = datetime.datetime.now()\n",
        "    diff = et-st\n",
        "    time_period.append(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo4Sl5k9yNQb"
      },
      "source": [
        "time_period"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRvmFpZByOht"
      },
      "source": [
        "max(time_period)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CjBXVhPyY1j"
      },
      "source": [
        "**0.7**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bFWiec2yYcg"
      },
      "source": [
        "itemset = []\n",
        "with open('/content/data/sign.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        itemset.append(temp)\n",
        "\n",
        "global_min_sup = 0.7\n",
        "total_partition = 5\n",
        "global_min_count = int(len(itemset)/total_partition)\n",
        "\n",
        "time_period = []\n",
        "if total_partition == math.ceil(total_partition):\n",
        "  for i in range(total_partition):\n",
        "    start = i*global_min_count\n",
        "    end = start + global_min_count\n",
        "    if end > len(itemset):\n",
        "      end = len(itemset)\n",
        "    partition  = itemset[start:end].copy()\n",
        "    st = datetime.datetime.now()\n",
        "    temp_min_sup = (((len(itemset)*global_min_sup))/total_partition)/float(len(partition))\n",
        "    gen_freq_itemset(partition,temp_min_sup)\n",
        "    et = datetime.datetime.now()\n",
        "    diff = et-st\n",
        "    time_period.append(diff.total_seconds()/60.0)\n",
        "else:\n",
        "  total_partition = math.ceil(total_partition)\n",
        "  for i in range(total_partition):\n",
        "    start = i*global_min_count\n",
        "    end = start + global_min_count\n",
        "    if end > len(itemset):\n",
        "      end = len(itemset)\n",
        "    partition  = itemset[start:end].copy()\n",
        "    st = datetime.datetime.now()\n",
        "    temp_min_sup = (((len(itemset)*global_min_sup))/total_partition)/float(len(partition))\n",
        "    gen_freq_itemset(partition,temp_min_sup)\n",
        "    et = datetime.datetime.now()\n",
        "    diff = et-st\n",
        "    time_period.append(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjjHTFWFyhez"
      },
      "source": [
        "time_period"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfeTsuCxyicf"
      },
      "source": [
        "max(time_period)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSkilKsRdjCR"
      },
      "source": [
        "##Leviathan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGINphLdCMJk"
      },
      "source": [
        "**0.7**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhqw-1r3pBkE"
      },
      "source": [
        "itemset = []\n",
        "with open('/content/data/Leviathan.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        itemset.append(temp)\n",
        "\n",
        "global_min_sup = 0.7\n",
        "total_partition = 10\n",
        "global_min_count = int(len(itemset)/total_partition)\n",
        "\n",
        "time_period = []\n",
        "if total_partition == math.ceil(total_partition):\n",
        "  for i in range(total_partition):\n",
        "    start = i*global_min_count\n",
        "    end = start + global_min_count\n",
        "    if end > len(itemset):\n",
        "      end = len(itemset)\n",
        "    partition  = itemset[start:end].copy()\n",
        "    st = datetime.datetime.now()\n",
        "    temp_min_sup = (((len(itemset)*global_min_sup))/total_partition)/float(len(partition))\n",
        "    gen_freq_itemset(partition,temp_min_sup)\n",
        "    et = datetime.datetime.now()\n",
        "    diff = et-st\n",
        "    time_period.append(diff.total_seconds()/60.0)\n",
        "else:\n",
        "  total_partition = math.ceil(total_partition)\n",
        "  for i in range(total_partition):\n",
        "    start = i*global_min_count\n",
        "    end = start + global_min_count\n",
        "    if end > len(itemset):\n",
        "      end = len(itemset)\n",
        "    partition  = itemset[start:end].copy()\n",
        "    st = datetime.datetime.now()\n",
        "    temp_min_sup = (((len(itemset)*global_min_sup))/total_partition)/float(len(partition))\n",
        "    gen_freq_itemset(partition,temp_min_sup)\n",
        "    et = datetime.datetime.now()\n",
        "    diff = et-st\n",
        "    time_period.append(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXnU5JtEIYX9"
      },
      "source": [
        "time_period"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCb-5du1Iak9"
      },
      "source": [
        "max(time_period)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6b0odtbKEDq"
      },
      "source": [
        "**0.6**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydrIQ8_SKFuv"
      },
      "source": [
        "itemset = []\n",
        "with open('/content/data/Leviathan.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        itemset.append(temp)\n",
        "\n",
        "global_min_sup = 0.6\n",
        "total_partition = 10\n",
        "global_min_count = int(len(itemset)/total_partition)\n",
        "\n",
        "time_period = []\n",
        "if total_partition == math.ceil(total_partition):\n",
        "  for i in range(total_partition):\n",
        "    start = i*global_min_count\n",
        "    end = start + global_min_count\n",
        "    if end > len(itemset):\n",
        "      end = len(itemset)\n",
        "    partition  = itemset[start:end].copy()\n",
        "    st = datetime.datetime.now()\n",
        "    temp_min_sup = (((len(itemset)*global_min_sup))/total_partition)/float(len(partition))\n",
        "    gen_freq_itemset(partition,temp_min_sup)\n",
        "    et = datetime.datetime.now()\n",
        "    diff = et-st\n",
        "    time_period.append(diff.total_seconds()/60.0)\n",
        "else:\n",
        "  total_partition = math.ceil(total_partition)\n",
        "  for i in range(total_partition):\n",
        "    start = i*global_min_count\n",
        "    end = start + global_min_count\n",
        "    if end > len(itemset):\n",
        "      end = len(itemset)\n",
        "    partition  = itemset[start:end].copy()\n",
        "    st = datetime.datetime.now()\n",
        "    temp_min_sup = (((len(itemset)*global_min_sup))/total_partition)/float(len(partition))\n",
        "    gen_freq_itemset(partition,temp_min_sup)\n",
        "    et = datetime.datetime.now()\n",
        "    diff = et-st\n",
        "    time_period.append(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfoQhim1KLil"
      },
      "source": [
        "time_period"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3P_dH9uKMnq"
      },
      "source": [
        "max(time_period)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQakL-djKkz3"
      },
      "source": [
        "**0.5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCpDVqONKkd8"
      },
      "source": [
        "itemset = []\n",
        "with open('/content/data/Leviathan.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        itemset.append(temp)\n",
        "\n",
        "global_min_sup = 0.5\n",
        "total_partition = 10\n",
        "global_min_count = int(len(itemset)/total_partition)\n",
        "\n",
        "time_period = []\n",
        "if total_partition == math.ceil(total_partition):\n",
        "  for i in range(total_partition):\n",
        "    start = i*global_min_count\n",
        "    end = start + global_min_count\n",
        "    if end > len(itemset):\n",
        "      end = len(itemset)\n",
        "    partition  = itemset[start:end].copy()\n",
        "    st = datetime.datetime.now()\n",
        "    temp_min_sup = (((len(itemset)*global_min_sup))/total_partition)/float(len(partition))\n",
        "    gen_freq_itemset(partition,temp_min_sup)\n",
        "    et = datetime.datetime.now()\n",
        "    diff = et-st\n",
        "    time_period.append(diff.total_seconds()/60.0)\n",
        "else:\n",
        "  total_partition = math.ceil(total_partition)\n",
        "  for i in range(total_partition):\n",
        "    start = i*global_min_count\n",
        "    end = start + global_min_count\n",
        "    if end > len(itemset):\n",
        "      end = len(itemset)\n",
        "    partition  = itemset[start:end].copy()\n",
        "    st = datetime.datetime.now()\n",
        "    temp_min_sup = (((len(itemset)*global_min_sup))/total_partition)/float(len(partition))\n",
        "    gen_freq_itemset(partition,temp_min_sup)\n",
        "    et = datetime.datetime.now()\n",
        "    diff = et-st\n",
        "    time_period.append(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM48Ep7sKxQv"
      },
      "source": [
        "time_period"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPhRY9z7K1af"
      },
      "source": [
        "max(time_period)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxP9gGWS-3Z8"
      },
      "source": [
        "##Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaTGWsoLsc0a"
      },
      "source": [
        "##SIgn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ayI7EIznDZ1"
      },
      "source": [
        "0.9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4QcK7nIfsIy"
      },
      "source": [
        "itemset = []\n",
        "st = datetime.datetime.now()\n",
        "with open('/content/data/sign.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        itemset.append(temp)\n",
        "\n",
        "a = list(apriori(itemset,min_support=0.9))\n",
        "end = datetime.datetime.now()\n",
        "diff = end - st\n",
        "print(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNrVgRAsnIMt"
      },
      "source": [
        "**0.8**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3KIFMJAnK5R"
      },
      "source": [
        "itemset = []\n",
        "st = datetime.datetime.now()\n",
        "with open('/content/data/sign.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        itemset.append(temp)\n",
        "\n",
        "a = list(apriori(itemset,min_support=0.8))\n",
        "end = datetime.datetime.now()\n",
        "diff = end - st\n",
        "print(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz156-krnNPW"
      },
      "source": [
        "**0.7**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX-BQK5unPjJ"
      },
      "source": [
        "itemset = []\n",
        "st = datetime.datetime.now()\n",
        "with open('/content/data/sign.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        itemset.append(temp)\n",
        "\n",
        "a = list(apriori(itemset,min_support=0.7))\n",
        "end = datetime.datetime.now()\n",
        "diff = end - st\n",
        "print(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCaoOOH8s-56"
      },
      "source": [
        "##Leviathan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cucejpifn-rd"
      },
      "source": [
        "**0.7**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq_uSrF3Dwho"
      },
      "source": [
        "itemset = []\n",
        "st = datetime.datetime.now()\n",
        "with open('/content/data/Leviathan.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        itemset.append(temp)\n",
        "\n",
        "a = list(apriori(itemset,min_support=0.7))\n",
        "end = datetime.datetime.now()\n",
        "diff = end - st\n",
        "print(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXZE20aKtjvx"
      },
      "source": [
        "**0.6**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mmKJBJCtIgJ"
      },
      "source": [
        "itemset = []\n",
        "st = datetime.datetime.now()\n",
        "with open('/content/data/Leviathan.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        itemset.append(temp)\n",
        "\n",
        "a = list(apriori(itemset,min_support=0.6))\n",
        "end = datetime.datetime.now()\n",
        "diff = end - st\n",
        "print(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IPAk4Jew1Jl"
      },
      "source": [
        "**0.5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6aAQc1qtqz1"
      },
      "source": [
        "itemset = []\n",
        "st = datetime.datetime.now()\n",
        "with open('/content/data/Leviathan.txt', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        temp = [i.strip() for i in row[0].split('-1')]\n",
        "        if temp[-1] != '-2':\n",
        "          print('wrong')\n",
        "        temp.pop()\n",
        "        itemset.append(temp)\n",
        "\n",
        "a = list(apriori(itemset,min_support=0.5))\n",
        "end = datetime.datetime.now()\n",
        "diff = end - st\n",
        "print(diff.total_seconds()/60.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c_hNjnFDBLD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}